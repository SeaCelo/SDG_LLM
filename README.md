# SDG_LLM
Developing synthetic data for use in SDG classifiers

## Synthetic Texts Generated by the LLM

There are 537 prompts to generate text for each of the 17 SDGs (17 × 537 = 9,129 synthetic texts). The 537 prompts are generated using two LLM models: ChatGPT and Claude3. This results in a total of **18,258 synthetic texts**.

### Sources
Variation is created by requesting the LLMs to generate texts in the style of each of the 537 sources:
* UN agencies, departments, and divisions
* The top 100 economists in the REPEC list [https://ideas.repec.org/top/top.person.all.html](https://ideas.repec.org/top/top.person.all.html)  
* English-language newspaper columnists from Wikipedia [https://en.wikipedia.org/wiki/List_of_newspaper_columnists](https://en.wikipedia.org/wiki/List_of_newspaper_columnists)  
* Development aid agencies from Wikipedia [https://en.wikipedia.org/wiki/List_of_development_aid_agencies](https://en.wikipedia.org/wiki/List_of_development_aid_agencies)  
* Finance and general magazines in the US and top newspapers [https://en.wikipedia.org/wiki/List_of_United_States_magazines](https://en.wikipedia.org/wiki/List_of_United_States_magazines) and [https://en.wikipedia.org/wiki/List_of_newspapers_in_the_United_States](https://en.wikipedia.org/wiki/List_of_newspapers_in_the_United_States)  
* The top 50 academic journals [https://ideas.repec.org/top/top.journals.all.html](https://ideas.repec.org/top/top.journals.all.html)  

### LLM Models Used
The synthetic texts are created using two different LLM models (ChatGPT and Claude3), each introducing its own method of generating texts, which serves as an additional source of variation. 

#### ChatGPT Model
* **Approach:** ChatGPT generates texts for each of the 17 SDGs using a combination of a general prompt and prompts tailored to reflect the style of specific sources. This model captures a wide range of stylistic and contextual nuances.
* **Outputs:** This model creates 9,129 synthetic texts.
* **Details:** The process and prompt strategy are explained in the file `gpt_separates.py`.

#### Anthropic Claude3 Model
* **Approach:** The Anthropic Claude model uses the Anthropic Claude 3 API to generate texts for each SDG. Like the ChatGPT model, it combines a general prompt with prompts tailored to specific sources, producing contextually rich and varied responses. The model used is `claude-3-opus-20240229`. 
* **Outputs:** This model also creates 9,129 synthetic texts.
* **Details:** The process and prompt strategy are explained in the file `anthro3_new_separates.py`.

### Pre-Labeling of Texts
Each text is pre-labeled according to the SDG it was generated for, based on the prompt request. However, this labeling reflects the **primary focus** of the text rather than an exclusive discussion of that SDG. Since the SDGs are inherently interconnected, discussions of any specific SDG often touch upon other related SDGs. This interconnectedness is reflected in the content, making the texts rich in cross-SDG insights.

### Organization and Naming Convention
The texts are organized in folders by SDG, and their filenames indicate both the SDG and the specific prompt used to generate them. The naming format is as follows:  
```
d_<SDG_number>_<prompt_number>_<llm>.txt
```
For example:  
* `d_2_14_chatgpt.txt` indicates that the text is about **SDG 2** and was created using the **14th prompt** and the **Chat GPT** LLM.  
This systematic naming ensures easy identification and retrieval of texts based on their SDG and the specific prompt variation used.

By using these two LLM models and recognizing the SDG interconnections, the dataset captures a broad range of stylistic and thematic diversity, enhancing its utility for training, testing, and analysis.

### Example of Evaluating Model Performance
We used **[SDGClassy](https://github.com/SeaCelo/SDGclassy)** to evaluate the dataset’s effectiveness in training a classification model for SDG-specific texts. This example specifically uses the synthetic texts generated by the Claude3 model.

#### Results
The model demonstrated excellent performance, with the following key metrics:
- **Accuracy:** 99%
- **Macro Average (across all SDGs):** Precision 0.99, Recall 0.99, F1-score 0.99
- **Weighted Average:** Precision 0.99, Recall 0.99, F1-score 0.99

Unweighted confusion matrix for the classification model's performance on the Claude3 synthetic texts:

![Confusion Matrix](image.png)
